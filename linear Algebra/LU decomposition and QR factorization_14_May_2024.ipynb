{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9Y0Eg1KaDx9"
   },
   "source": [
    "# LU decomposition and QR factorization\n",
    "LU decomposition and QR factorization are common techniques in linear algebra for solving linear equations, inverting matrices, and computing determinants efficiently. Below are examples of how to perform these decompositions in Python using the NumPy and SciPy libraries.\n",
    "\n",
    "LU Decomposition is typically more complex, and for practical purposes, using a library is recommended. Here’s a brief outline of the algorithm, but note that implementing this correctly and efficiently from scratch is non-trivial:\n",
    "\n",
    "- **Initialize $ L $ and $ U $**: Start with $ L $ as the identity matrix and $ U $ as a copy of $ A $.\n",
    "- **Gaussian Elimination Process**: For each element below the diagonal in $ U $ (i.e., $ U_{ij} $ where $ i > j $), calculate the factor $ L_{ij} = U_{ij} / U_{jj} $ and store it in $ L $. Use $ L_{ij} $ to subtract the appropriate multiple of row $ j $ from row $ i $ in $ U $, setting $ U_{ij} $ to zero, which effectively performs the elimination process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9Y0Eg1KaDx9"
   },
   "source": [
    "## 1. LU Decomposition\n",
    "\n",
    "**Definition:**\n",
    "LU decomposition factors a matrix $A$ into the product of a lower triangular matrix $L$ and an upper triangular matrix $U$.\n",
    "\n",
    "$$ A = LU $$\n",
    "\n",
    "- **L** is a lower triangular matrix with unit diagonal elements (in some definitions, the diagonal elements can be arbitrary).\n",
    "- **U** is an upper triangular matrix.\n",
    "\n",
    "**Purpose:**\n",
    "LU decomposition is used for solving linear systems, computing determinants, and inverting matrices.\n",
    "\n",
    "**Characteristics:**\n",
    "- Generally applied to square matrices ($n \\times n$).\n",
    "- May require row permutations (pivoting) to ensure numerical stability, leading to $PA = LU$ where $P$ is a permutation matrix.\n",
    "\n",
    "**Applications:**\n",
    "- Efficiently solving multiple linear systems with the same coefficient matrix.\n",
    "- Matrix inversion.\n",
    "- Computing determinants: $\\det(A) = \\det(L) \\cdot \\det(U)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9Y0Eg1KaDx9"
   },
   "source": [
    "LU Decomposition factors a matrix as the product of a lower triangular matrix and an upper triangular matrix (along with a permutation matrix). Here's how you can do this in Python using the `scipy.linalg.lu` function.\n",
    "\n",
    "In the case below, `A` is the matrix you want to decompose, and `P`, `L`, and `U` are the permutation, lower triangular, and upper triangular matrices, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75lpy8ZvZ8z5",
    "outputId": "ac9a2775-559a-4703-e3f2-9233493675e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix:\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8 10]]\n",
      "\n",
      "P = \n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "\n",
      "L = \n",
      "[[1.         0.         0.        ]\n",
      " [0.14285714 1.         0.        ]\n",
      " [0.57142857 0.5        1.        ]]\n",
      "\n",
      "U = \n",
      "[[ 7.          8.         10.        ]\n",
      " [ 0.          0.85714286  1.57142857]\n",
      " [ 0.          0.         -0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "# Define a square matrix\n",
    "A = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 10]\n",
    "])\n",
    "\n",
    "# Perform LU decomposition\n",
    "P, L, U = lu(A)\n",
    "\n",
    "print(\"Original Matrix:\")\n",
    "print(A)\n",
    "print(\"\\nP = \")\n",
    "print(P)\n",
    "print(\"\\nL = \")\n",
    "print(L)\n",
    "print(\"\\nU = \")\n",
    "print(U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction\n",
    "Once you have the matrices $ P $, $ L $, and $ U $ from an LU decomposition, reconstructing the original matrix $ A $ involves a simple matrix multiplication of these components. However, it's important to remember that $ P $ is a permutation matrix, which represents row interchanges made during the LU decomposition for numerical stability.\n",
    "\n",
    "To reconstruct the matrix $ A $ from its LU decomposition components, you multiply $ P $, $ L $, and $ U $ in that specific order: $ A = P \\times L \\times U $.\n",
    "\n",
    "Here’s how you can do this in Python using the NumPy library, assuming you have already decomposed $ A $ into $ P $, $ L $, and $ U $ using the SciPy library:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-Step Code to Reconstruct $ A $ from $ P $, $ L $, and $ U $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reconstruct $ A $ Using Matrix Multiplication**\n",
    "\n",
    "Use NumPy's `dot` function to multiply $ P $, $ L $, and $ U $ in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.],\n",
       "       [ 7.,  8., 10.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_reconstructed = np.dot(P, np.dot(L, U))\n",
    "A_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uq0WtLB7Z8Zk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-ws1joUa6IC"
   },
   "source": [
    "## 2. QR Factorization\n",
    "\n",
    "\n",
    "**Definition:**\n",
    "QR-factorization decomposes a matrix $A$ into a product of an orthogonal matrix $Q$ and an upper triangular matrix $R$.\n",
    "\n",
    "$$ A = QR $$\n",
    "\n",
    "- **Q** is an orthogonal matrix (or unitary if $A$ is complex), meaning $Q^T Q = I$.\n",
    "- **R** is an upper triangular matrix.\n",
    "\n",
    "**Purpose:**\n",
    "QR-factorization is primarily used for solving linear systems, least squares problems, and for computing eigenvalues. \n",
    "\n",
    "**Characteristics:**\n",
    "- Applicable to any $m \\times n$ matrix.\n",
    "- Preserves orthogonality.\n",
    "- Often used in iterative algorithms, such as the QR algorithm for finding eigenvalues.\n",
    "\n",
    "**Applications:**\n",
    "- Solving linear systems: $Ax = b \\rightarrow QRx = b$\n",
    "- Least squares problems: Minimizing $\\|Ax - b\\|$ for overdetermined systems.\n",
    "\n",
    "QR factorization decomposes a matrix into a product of an orthogonal matrix and an upper triangular matrix. Here's how you can perform QR factorization using NumPy with the `numpy.linalg.qr` function.\n",
    "\n",
    "In the code below, `A` is the matrix you want to factorize, and `Q` and `R` are the orthogonal and upper triangular matrices, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlGZHwJjZ7_9",
    "outputId": "0eebfe80-c62e-48bb-be5b-360fafa1837e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix:\n",
      "[[ 12 -51   4]\n",
      " [  6 167 -68]\n",
      " [ -4  24 -41]]\n",
      "\n",
      "Q = \n",
      "[[-0.85714286  0.39428571  0.33142857]\n",
      " [-0.42857143 -0.90285714 -0.03428571]\n",
      " [ 0.28571429 -0.17142857  0.94285714]]\n",
      "\n",
      "R = \n",
      "[[ -14.  -21.   14.]\n",
      " [   0. -175.   70.]\n",
      " [   0.    0.  -35.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a matrix\n",
    "A = np.array([\n",
    "    [12, -51, 4],\n",
    "    [6, 167, -68],\n",
    "    [-4, 24, -41]\n",
    "])\n",
    "\n",
    "# Perform QR factorization\n",
    "Q, R = np.linalg.qr(A)\n",
    "\n",
    "print(\"Original Matrix:\")\n",
    "print(A)\n",
    "print(\"\\nQ = \")\n",
    "print(Q)\n",
    "print(\"\\nR = \")\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ds8zQl-Db9Bn"
   },
   "source": [
    "## Applications of QR Factorization\n",
    "- Solving Linear Systems: QR factorization is particularly useful for solving linear systems that are overdetermined (more equations than unknowns) or when the matrix is square but poorly conditioned.\n",
    "\n",
    "- Least Squares Regression: In statistics and machine learning, QR factorization is used to solve least squares problems efficiently, which is crucial for linear regression models.\n",
    "\n",
    "- Eigenvalue Computations: In numerical algorithms, QR factorization is a common method for finding the eigenvalues of a matrix, especially when combined with shift strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgbXmzI0cAPr"
   },
   "source": [
    "# MAtrix Inverse using LU Decomposition\n",
    "\n",
    "LU decomposition can be utilized to calculate the inverse of a matrix \\( A \\) efficiently. The basic idea is to use the LU decomposition of \\( A \\) to solve the system \\( AX = I \\) for \\( X \\), where \\( I \\) is the identity matrix, and \\( X \\) will be the inverse of \\( A \\).\n",
    "\n",
    "Here's a step-by-step breakdown:\n",
    "\n",
    "1. Decompose the matrix \\( A \\) into its LU components: \\( A = LU \\).\n",
    "2. For each column \\( i \\) of the identity matrix \\( I \\):\n",
    "    - a. Solve the lower triangular system \\( LY = I[:,i] \\) for \\( Y \\).\n",
    "    - b. Solve the upper triangular system \\( UX = Y \\) for \\( X \\).\n",
    "    - c. The resulting \\( X \\) is the \\( i^{th} \\) column of \\( A^{-1} \\).\n",
    "\n",
    "Remember, not all matrices have an inverse. If \\( A \\) is singular, then this process won't provide a meaningful result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da4e8L4QmotB",
    "outputId": "952aa0ab-9ccc-4fe2-f288-95f215c462a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse using LU decomposition:\n",
      "[[-0.66666667 -1.33333333  1.        ]\n",
      " [-0.66666667  3.66666667 -2.        ]\n",
      " [ 1.         -2.          1.        ]]\n",
      "\n",
      "Inverse using NumPy:\n",
      "[[-0.66666667 -1.33333333  1.        ]\n",
      " [-0.66666667  3.66666667 -2.        ]\n",
      " [ 1.         -2.          1.        ]]\n",
      "\n",
      "Both methods give approximately the same result.\n",
      "\n",
      "Validation by multiplying the original matrix by its inverse:\n",
      "[[1.00000000e+00 0.00000000e+00 1.11022302e-16]\n",
      " [0.00000000e+00 1.00000000e+00 2.22044605e-16]\n",
      " [8.88178420e-16 0.00000000e+00 1.00000000e+00]]\n",
      "\n",
      "The result is approximately an identity matrix. The minor discrepancies are due to floating-point precision.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lu_factor, lu_solve\n",
    "\n",
    "def matrix_inverse_using_lu(A):\n",
    "    # Retrieve the number of rows (or columns) for the square matrix A\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Perform LU decomposition on the input matrix A.\n",
    "    # 'lu' is the combined form of lower and upper triangular matrices.\n",
    "    # 'piv' holds the pivot indices showing row swaps made during the decomposition process.\n",
    "    lu, piv = lu_factor(A)\n",
    "\n",
    "    # Create an identity matrix of size 'n x n'. This matrix serves as the right-hand side\n",
    "    # of the equation system to be solved for finding the inverse. Each column in the identity\n",
    "    # matrix is used in turn to solve the equation system.\n",
    "    I = np.eye(n)\n",
    "\n",
    "    # Initialize an empty matrix of zeros with the same shape as A to store the inverse.\n",
    "    # The data type is specified as float64 for higher precision.\n",
    "    invA = np.zeros_like(A, dtype=np.float64)\n",
    "\n",
    "    # Iterate over each column of the identity matrix.\n",
    "    for i in range(n):\n",
    "        # For each column, solve the equation system 'Ax = I[:, i]' where 'A' is the original\n",
    "        # matrix, 'x' is the column vector of the inverse we are solving for, and 'I[:, i]'\n",
    "        # is the current column of the identity matrix.\n",
    "        # The function 'lu_solve' is used with the LU decomposition results and the current\n",
    "        # column of the identity matrix to find each 'x' (each column of the inverse matrix).\n",
    "        invA[:, i] = lu_solve((lu, piv), I[:, i])\n",
    "\n",
    "    # After finding all columns of the inverse matrix, return the completed inverse.\n",
    "    return invA\n",
    "\n",
    "# Define a matrix\n",
    "A = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 10]\n",
    "], dtype=np.float64)  # Ensure the dtype is float for precision\n",
    "\n",
    "# Calculate the inverse using LU decomposition\n",
    "A_inv_lu = matrix_inverse_using_lu(A)\n",
    "\n",
    "# Using NumPy's built-in function to find the inverse\n",
    "A_inv_np = np.linalg.inv(A)\n",
    "\n",
    "# Print the results\n",
    "print(\"Inverse using LU decomposition:\")\n",
    "print(A_inv_lu)\n",
    "print(\"\\nInverse using NumPy:\")\n",
    "print(A_inv_np)\n",
    "\n",
    "# Verify if the results are approximately equal\n",
    "if np.allclose(A_inv_lu, A_inv_np):\n",
    "    print(\"\\nBoth methods give approximately the same result.\")\n",
    "else:\n",
    "    print(\"\\nResults are different.\")\n",
    "\n",
    "# Validation by checking A_inv * A = I\n",
    "print(\"\\nValidation by multiplying the original matrix by its inverse:\")\n",
    "result = np.dot(A, A_inv_lu)\n",
    "print(result)\n",
    "\n",
    "# Check if the result is close to the identity matrix\n",
    "identity_matrix = np.eye(A.shape[0])\n",
    "if np.allclose(result, identity_matrix):\n",
    "    print(\"\\nThe result is approximately an identity matrix. The minor discrepancies are due to floating-point precision.\")\n",
    "else:\n",
    "    print(\"\\nThe result significantly deviates from an identity matrix. There may be an issue with the calculations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJnmZRv4ouic",
    "outputId": "50a0b007-5ea3-4074-a1bb-8e5b8ebf4b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix:\n",
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8. 10.]]\n",
      "\n",
      "Inverse Matrix:\n",
      "[[-0.66666667 -1.33333333  1.        ]\n",
      " [-0.66666667  3.66666667 -2.        ]\n",
      " [ 1.         -2.          1.        ]]\n",
      "\n",
      "A * A_inv:\n",
      "[[1.00000000e+00 0.00000000e+00 1.11022302e-16]\n",
      " [0.00000000e+00 1.00000000e+00 2.22044605e-16]\n",
      " [8.88178420e-16 0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.linalg as la\n",
    "import numpy as np\n",
    "\n",
    "def inverse_via_lu(A):\n",
    "    # Step 1: Perform LU Decomposition\n",
    "    P, L, U = la.lu(A)\n",
    "\n",
    "    # Step 2: Solve for the inverse\n",
    "    n = A.shape[0]\n",
    "    I = np.eye(n)\n",
    "    A_inv = np.zeros_like(A)\n",
    "\n",
    "    for i in range(n):\n",
    "        b = I[:, i]  # This selects the i-th column of the Identity matrix\n",
    "        y = la.solve_triangular(L, np.dot(P.T, b), lower=True)  # Solve Ly = Pb for y\n",
    "        x = la.solve_triangular(U, y, lower=False)  # Now solve Ux = y for x\n",
    "        A_inv[:, i] = x  # Place the solution in the appropriate column\n",
    "\n",
    "    return A_inv\n",
    "\n",
    "# Define a matrix\n",
    "A = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 10]\n",
    "], dtype=np.float64)  # Ensure the dtype is float for precision\n",
    "\n",
    "A_inv = inverse_via_lu(A)\n",
    "\n",
    "print(\"Original Matrix:\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\nInverse Matrix:\")\n",
    "print(A_inv)\n",
    "\n",
    "# Verification: multiplying a matrix by its inverse should yield the identity matrix\n",
    "print(\"\\nA * A_inv:\")\n",
    "print(np.dot(A, A_inv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOqM_S-xpUp5"
   },
   "source": [
    "This function first decomposes the matrix `A` into `P`, `L`, and `U` matrices (permutation, lower, and upper triangular matrices, respectively). It then solves the system of equations Ly = Pb and Ux = y for each column of the identity matrix, effectively solving the equation Ax = I, where `I` is the identity matrix. The solutions `x` are the columns of the inverse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOgxm_57pfvC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uN1g1ioWphgc"
   },
   "source": [
    "# Summary of Differences between LU, QR & SVD\n",
    "\n",
    "1. **Matrix Types:**\n",
    "   - QR: Applicable to any $m \\times n$ matrix.\n",
    "   - LU: Typically applied to square matrices ($n \\times n$).\n",
    "   - SVD: Applicable to any $m \\times n$ matrix.\n",
    "\n",
    "2. **Components:**\n",
    "   - QR: Orthogonal matrix $Q$ and upper triangular matrix $R$.\n",
    "   - LU: Lower triangular matrix $L$ and upper triangular matrix $U$.\n",
    "   - SVD: Orthogonal matrices $U$ and $V$, and diagonal matrix $\\Sigma$.\n",
    "\n",
    "3. **Orthogonality:**\n",
    "   - QR and SVD involve orthogonal (or unitary) matrices.\n",
    "   - LU does not involve orthogonal matrices.\n",
    "\n",
    "4. **Applications:**\n",
    "   - QR: Solving linear systems, eigenvalue computation, least squares.\n",
    "   - LU: Solving linear systems, matrix inversion, computing determinants.\n",
    "   - SVD: Low-rank approximations, pseudoinverses, PCA, data compression.\n",
    "\n",
    "5. **Numerical Stability:**\n",
    "   - QR and SVD are generally more numerically stable compared to LU, especially without pivoting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TK7uorOXpg5G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
